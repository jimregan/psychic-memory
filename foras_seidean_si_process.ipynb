{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524415b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pdfminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac60ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('seidean_si.json') as infile:\n",
    "    books = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85352f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for book in books.keys():\n",
    "    for dialect in books[book].keys():\n",
    "        tmp = {}\n",
    "        url = books[book][dialect]\n",
    "        tmp['url'] = url\n",
    "        tmp['file'] = url.split('/')[-1]\n",
    "        books[book][dialect] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83c5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = {\n",
    "    \"Táimid mór le Chéile\": [i for i in range(4, 20)],\n",
    "    \"Cliabhán d'Ailbhe\": [i for i in range(3, 38)],\n",
    "    \"Murach an Traenáil ar fad\": [i for i in range(4, 37)],\n",
    "    \"Ná lig dóibh éalú\": [i for i in range(5, 40)],\n",
    "    \"Céard é sin?\": [i for i in range(4, 30)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7bc66991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    import re\n",
    "    clean = list()\n",
    "    for line in text.split('\\n'):\n",
    "        trimmed = line.strip()\n",
    "        if trimmed == '':\n",
    "            continue\n",
    "        # skip page numbers\n",
    "        if re.search(r'^[0-9]+$', trimmed):\n",
    "            continue\n",
    "        if '.indd' in trimmed:\n",
    "            continue\n",
    "        if '14/11/2006' in trimmed:\n",
    "            continue\n",
    "        if trimmed in ['Is fada liom go', 'dtiocfaidh an Satharn.']:\n",
    "            continue\n",
    "        clean.append(trimmed)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9524d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(cleaned):\n",
    "    from mosestokenizer import MosesSentenceSplitter\n",
    "    with MosesSentenceSplitter('en') as splitsents:\n",
    "        split=splitsents(cleaned)\n",
    "    return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8d6472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_quote(text):\n",
    "    return re.search(\"‘\", text) and not re.search(\"’\", text)\n",
    "def close_quote(text):\n",
    "    return re.search(\"’\", text) and not re.search(\"‘\", text)\n",
    "def fix_split(cleaned):\n",
    "    resplit = list()\n",
    "    i = 0\n",
    "    while i < len(cleaned):\n",
    "        if i < len(cleaned) -1 and open_quote(cleaned[i]) and close_quote(cleaned[i+1]):\n",
    "            resplit.append(f'{cleaned[i]} {cleaned[i+1]}')\n",
    "            i = i + 2\n",
    "        else:\n",
    "            resplit.append(cleaned[i])\n",
    "            i = i + 1\n",
    "    return resplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd01b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for book in pages.keys():\n",
    "    page_range = pages.get(book)\n",
    "    for dialect in books[book].keys():\n",
    "        file = books[book][dialect]['file']\n",
    "        text = extract_text(file, page_numbers=page_range)\n",
    "        if file == '1ab98add8018901db52fd0fdf4a63e7c.pdf':\n",
    "            v=clean_text(text)\n",
    "            v[114], v[115] = v[115], v[114]\n",
    "            v[53], v[54] = v[54], v[53]\n",
    "            books[book][dialect]['lines'] = fix_split(split_sentences(v))\n",
    "        elif file == 'd40b6b41054d6508191c167c9fd554cd.pdf':\n",
    "            v=clean_text(text)\n",
    "            v[114], v[115] = v[115], v[114]\n",
    "            books[book][dialect]['lines'] = fix_split(split_sentences(v))\n",
    "        elif file == '23f7240dba59deace40be7dec0a814a2.pdf':\n",
    "            v=clean_text(text)\n",
    "            v[54], v[55] = v[55], v[54]\n",
    "            v[73], v[74] = v[74], v[73]\n",
    "            v[118], v[119] = v[119], v[118]\n",
    "            books[book][dialect]['lines'] = fix_split(split_sentences(v))\n",
    "        else:\n",
    "            books[book][dialect]['lines'] = fix_split(split_sentences(clean_text(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03e965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c82f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moleabharsac_footer_starts(line):\n",
    "    for i in ['Ócáidí Speisialta –', 'An Scoil –', 'Sa Bhaile –', 'Siopadóireacht –', 'Mé Féin –', 'Caitheamh Aimsire –']:\n",
    "        if line.startswith(i):\n",
    "            return True\n",
    "    return False\n",
    "def clean_moleabharsac(text, page):\n",
    "    lines = []\n",
    "    if page in [8, 9, 20]:\n",
    "        return lines\n",
    "    is_even = (page % 2) == 0\n",
    "    trimmed = [line.strip() for line in text.split('\\n')]\n",
    "    if page in [1]:\n",
    "        return trimmed[0:2]\n",
    "    for line in trimmed:\n",
    "        if line == '':\n",
    "            continue\n",
    "        if re.search(r'^[0-9]+$', line):\n",
    "            if is_even and page == int(line):\n",
    "                return lines\n",
    "            else:\n",
    "                continue\n",
    "        if re.search(r'^_+$', line):\n",
    "            continue\n",
    "        if '–' in line and moleabharsac_footer_starts(line):\n",
    "            return lines\n",
    "        if line == 'Mo Leabharsa - First Class':\n",
    "            return lines\n",
    "        lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec78b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "test_pdf = '6c319b3865d18f84101d42193367f716.pdf'\n",
    "outputs = dict()\n",
    "for i in range(4, 57):\n",
    "    text = extract_text(test_pdf, page_numbers=[i])\n",
    "    outputs[i] = text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad26391",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_moleabharsac(outputs[25], 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f28d5cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text('23f7240dba59deace40be7dec0a814a2.pdf', page_numbers=[i for i in range(5, 40)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
