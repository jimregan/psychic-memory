{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65765ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pdfminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998b0170",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('seidean_si.json') as infile:\n",
    "    books = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d349b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for book in books.keys():\n",
    "    for dialect in books[book].keys():\n",
    "        tmp = {}\n",
    "        url = books[book][dialect]\n",
    "        tmp['url'] = url\n",
    "        tmp['file'] = url.split('/')[-1]\n",
    "        books[book][dialect] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9bb487",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = {\n",
    "    \"Táimid mór le Chéile\": [i for i in range(4, 20)],\n",
    "    \"Cliabhán d'Ailbhe\": [i for i in range(3, 38)],\n",
    "    \"Murach an Traenáil ar fad\": [i for i in range(4, 37)],\n",
    "    \"Ná lig dóibh éalú\": [i for i in range(5, 40)],\n",
    "    \"Céard é sin?\": [i for i in range(4, 30)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "714c728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    import re\n",
    "    clean = list()\n",
    "    for line in text.split('\\n'):\n",
    "        trimmed = line.strip()\n",
    "        if trimmed == '':\n",
    "            continue\n",
    "        # skip page numbers\n",
    "        if re.search(r'^[0-9]+$', trimmed):\n",
    "            continue\n",
    "        if '.indd' in trimmed:\n",
    "            continue\n",
    "        if '14/11/2006' in trimmed:\n",
    "            continue\n",
    "        if 'ar fadl.in' in trimmed:\n",
    "            continue\n",
    "        if '14/08/2006' in trimmed:\n",
    "            continue\n",
    "        if trimmed in ['Is fada liom go', 'dtiocfaidh an Satharn.']:\n",
    "            continue\n",
    "        clean.append(trimmed)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed03c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(cleaned):\n",
    "    from mosestokenizer import MosesSentenceSplitter\n",
    "    with MosesSentenceSplitter('en') as splitsents:\n",
    "        split=splitsents(cleaned)\n",
    "    return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c290f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_quote(text):\n",
    "    return re.search(\"‘\", text) and not re.search(\"’\", text)\n",
    "def close_quote(text):\n",
    "    return re.search(\"’\", text) and not re.search(\"‘\", text)\n",
    "def fix_split(cleaned):\n",
    "    resplit = list()\n",
    "    i = 0\n",
    "    while i < len(cleaned):\n",
    "        if i < len(cleaned) -1 and open_quote(cleaned[i]) and close_quote(cleaned[i+1]):\n",
    "            resplit.append(f'{cleaned[i]} {cleaned[i+1]}')\n",
    "            i = i + 2\n",
    "        else:\n",
    "            resplit.append(cleaned[i])\n",
    "            i = i + 1\n",
    "    return resplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ae01b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "for book in pages.keys():\n",
    "    page_range = pages.get(book)\n",
    "    for dialect in books[book].keys():\n",
    "        file = books[book][dialect]['file']\n",
    "        text = extract_text(file, page_numbers=page_range)\n",
    "        if file == '1ab98add8018901db52fd0fdf4a63e7c.pdf':\n",
    "            v=clean_text(text)\n",
    "            v[114], v[115] = v[115], v[114]\n",
    "            v[53], v[54] = v[54], v[53]\n",
    "            books[book][dialect]['lines'] = fix_split(split_sentences(v))\n",
    "        elif file == 'd40b6b41054d6508191c167c9fd554cd.pdf':\n",
    "            v=clean_text(text)\n",
    "            v[114], v[115] = v[115], v[114]\n",
    "            books[book][dialect]['lines'] = fix_split(split_sentences(v))\n",
    "        elif file == '23f7240dba59deace40be7dec0a814a2.pdf':\n",
    "            v=clean_text(text)\n",
    "            v[54], v[55] = v[55], v[54]\n",
    "            v[73], v[74] = v[74], v[73]\n",
    "            v[118], v[119] = v[119], v[118]\n",
    "            books[book][dialect]['lines'] = fix_split(split_sentences(v))\n",
    "        elif file == 'df76a9acab68f481e3fc6ad09956364f.pdf':\n",
    "            v=clean_text(text)\n",
    "            v[72], v[73], v[74], v[75], v[76], v[77] = v[75], v[72], v[76], v[73], v[77], v[74]\n",
    "            v[128], v[129], v[130], v[131], v[132], v[133] = v[129], v[132], v[130], v[128], v[133], v[131]\n",
    "            v.pop(131)\n",
    "            books[book][dialect]['lines'] = fix_split(split_sentences(v))\n",
    "        elif file == '3c2baf4652793d8fb44c598731f1d0f8.pdf':\n",
    "            v=clean_text(text)\n",
    "            v[71], v[72] = v[72], v[71]\n",
    "            v.pop(123)\n",
    "            books[book][dialect]['lines'] = fix_split(split_sentences(v))\n",
    "        elif file == '899d2e69d0833496edf4dd8aa6f4e238.pdf':\n",
    "            v=clean_text(text)\n",
    "            v[73], v[74], v[75], v[76] = v[75], v[73], v[76], v[74]\n",
    "            v[125], v[126], v[127] = v[127], v[125], v[126]\n",
    "            v[133], v[132] = v[132], v[133]\n",
    "            v.pop(127)\n",
    "            books[book][dialect]['lines'] = fix_split(split_sentences(v))\n",
    "        else:\n",
    "            books[book][dialect]['lines'] = fix_split(split_sentences(clean_text(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5ad918e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Táimid mór le Chéile:\n",
      "\n",
      "C: 59\n",
      "M: 59\n",
      "U: 57\n",
      "\n",
      "\n",
      "Cliabhán d'Ailbhe:\n",
      "\n",
      "C: 129\n",
      "M: 129\n",
      "U: 130\n",
      "\n",
      "\n",
      "Murach an Traenáil ar fad:\n",
      "\n",
      "C: 72\n",
      "M: 72\n",
      "U: 73\n",
      "\n",
      "\n",
      "Ná lig dóibh éalú:\n",
      "\n",
      "C: 65\n",
      "M: 65\n",
      "U: 65\n",
      "\n",
      "\n",
      "Céard é sin?:\n",
      "\n",
      "C: 105\n",
      "M: 104\n",
      "U: 105\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for book in pages.keys():\n",
    "    print(f'{book}:\\n')\n",
    "    for dialect in books[book].keys():\n",
    "        linelen = len(books[book][dialect]['lines'])\n",
    "        print(f'{dialect}: {linelen}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca355677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moleabharsac_footer_starts(line):\n",
    "    for i in ['Ócáidí Speisialta –', 'An Scoil –', 'Sa Bhaile –', 'Siopadóireacht –', 'Mé Féin –', 'Caitheamh Aimsire –']:\n",
    "        if line.startswith(i):\n",
    "            return True\n",
    "    return False\n",
    "def clean_moleabharsac(text, page):\n",
    "    lines = []\n",
    "    if page in [8, 9, 20]:\n",
    "        return lines\n",
    "    is_even = (page % 2) == 0\n",
    "    trimmed = [line.strip() for line in text.split('\\n')]\n",
    "    if page in [1]:\n",
    "        return trimmed[0:2]\n",
    "    for line in trimmed:\n",
    "        if line == '':\n",
    "            continue\n",
    "        if re.search(r'^[0-9]+$', line):\n",
    "            if is_even and page == int(line):\n",
    "                return lines\n",
    "            else:\n",
    "                continue\n",
    "        if re.search(r'^_+$', line):\n",
    "            continue\n",
    "        if '–' in line and moleabharsac_footer_starts(line):\n",
    "            return lines\n",
    "        if line == 'Mo Leabharsa - First Class':\n",
    "            return lines\n",
    "        lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9f14c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "test_pdf = '6c319b3865d18f84101d42193367f716.pdf'\n",
    "outputs = dict()\n",
    "for i in range(4, 57):\n",
    "    text = extract_text(test_pdf, page_numbers=[i])\n",
    "    outputs[i] = text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffa8e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_moleabharsac(outputs[25], 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9e495449",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = extract_text('899d2e69d0833496edf4dd8aa6f4e238.pdf', page_numbers=[i for i in range(4, 37)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ba315769",
   "metadata": {},
   "outputs": [],
   "source": [
    "v=clean_text(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
